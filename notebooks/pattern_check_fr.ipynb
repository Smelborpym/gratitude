{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_t_matcher(patterns, nlp):\n",
    "    \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    [matcher.add(rule, [pattern]) for rule, pattern in patterns.items()] \n",
    "    \n",
    "    return matcher\n",
    "\n",
    "\n",
    "def run_baseline_fr(nlp, doc, t_matcher):\n",
    "    \n",
    "    appreciation = False\n",
    "    patterns = []\n",
    "    sequences = []\n",
    "    \n",
    "    praise = []\n",
    "    negated = [\"me remercie\", \"seigneur\"]\n",
    "    request = [\"pouvez-vous\", \"pourriez-vous\", \"peux-tu\", \"est-il possible\" , \"serait-il possible\", \"merci d'avance\"]\n",
    "    \n",
    "    t_matches = t_matcher(doc)\n",
    "    \n",
    "    request_match = []\n",
    "    if t_matches:\n",
    "        appreciation = True\n",
    "        for match_id, start, end in t_matches:\n",
    "            span = doc[start:end]\n",
    "            # discard the match if captured sequence is actually a request-Gratitude (e.g. Can you email me the file please? Thanks)\n",
    "            first_part = doc[:start].text.lower()\n",
    "            request_match = [x for x in request if x in first_part]\n",
    "            patterns.append(nlp.vocab.strings[match_id])\n",
    "            sequences.append(span.text)\n",
    "    \n",
    "    for text in praise:\n",
    "      if text in doc.text.lower():\n",
    "        appreciation = True\n",
    "    \n",
    "    \n",
    "    for text in negated:\n",
    "      if text in doc.text.lower():\n",
    "        appreciation = False\n",
    "    \n",
    "    if request_match:\n",
    "      appreciation = False\n",
    "    \n",
    "    \n",
    "    if appreciation:\n",
    "      return appreciation, patterns, sequences\n",
    "    else:\n",
    "      return appreciation, [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    \"je/nous/on - tenir - √† - vous/te/les/le/la - remercier\": [{\"LOWER\": {\"IN\": [\"je\", \"on\", \"nous\"]}}, {\"LEMMA\": \"tenir\"}, {\"LOWER\": \"√†\"},  {\"POS\": {\"IN\": [\"PRON\", \"DET\"]}}, {\"LEMMA\":\"remercier\"}],\n",
    "    \"je/nous/on - tenir - √† - remercier\": [{\"LOWER\": {\"IN\": [\"je\", \"on\", \"nous\"]}}, {\"LEMMA\": \"tenir\"}, {\"LOWER\": \"√†\"}, {\"LEMMA\":\"remercier\"}],\n",
    "    \"remerciement - adress√© - √†\": [{\"LEMMA\": {\"IN\": [\"remerciement\", \"gratitude\"]}}, {\"LEMMA\": \"adresser\"}, {\"LOWER\": \"√†\"}],\n",
    "    \"nos/mes - sinc√®res/... - remerciments/...\": [{\"LOWER\": {\"IN\": [\"notre\", \"mon\", \"nos\", \"mes\", \"ma\"]}}, {\"LOWER\": {\"IN\": [\"sinc√®res\", \"sinc√®re\"]}}, {\"LOWER\": {\"IN\": [\"gratitude\", \"remerciement\", \"remerciements\" ]}}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"En cette belle journ√©e pass√©e au royaume magique, je tiens √† remercier mille fois Broc√©liande-Nausicaa et C√©dric de la Tour de la Terreur\",\n",
    "    \"Vous souvenez-vous quand vous avez rejoint Twitter ? Moi, oui ! MonAnniversaireTwitter Que le temps passe vite. üò≠üò≠ je tiens √† vous remercier pour le soutien.\",\n",
    "    \"Nous tenons √† remercier USER pour sa contribution. Sans son soutien, nous ne pourrions pas garantir que le Canada dispose d'une strat√©gie de d√©pistage et de sensibilisation par et pour la communaut√©.\", \n",
    "    \"Remerciements adress√©s √† USER , USER et USER par tous ceux qui ont pris la parole, du repr√©sentant du site Kinyinya II au Conseiller du Gouverneur\",\n",
    "    \"Nos sinc√®res remerciements aux agents.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En cette belle journ√©e pass√©e au royaume magique, je tiens √† remercier mille fois Broc√©liande-Nausicaa et C√©dric de la Tour de la Terreur\n",
      "Token: En \tPOS:  ADP \tLemma:  en\n",
      "Token: cette \tPOS:  DET \tLemma:  ce\n",
      "Token: belle \tPOS:  ADJ \tLemma:  bel\n",
      "Token: journ√©e \tPOS:  NOUN \tLemma:  journ√©e\n",
      "Token: pass√©e \tPOS:  VERB \tLemma:  passer\n",
      "Token: au \tPOS:  ADP \tLemma:  au\n",
      "Token: royaume \tPOS:  NOUN \tLemma:  royaume\n",
      "Token: magique \tPOS:  ADJ \tLemma:  magique\n",
      "Token: , \tPOS:  PUNCT \tLemma:  ,\n",
      "Token: je \tPOS:  PRON \tLemma:  je\n",
      "Token: tiens \tPOS:  VERB \tLemma:  tenir\n",
      "Token: √† \tPOS:  ADP \tLemma:  √†\n",
      "Token: remercier \tPOS:  VERB \tLemma:  remercier\n",
      "Token: mille \tPOS:  NUM \tLemma:  mille\n",
      "Token: fois \tPOS:  NOUN \tLemma:  fois\n",
      "Token: Broc√©liande \tPOS:  ADJ \tLemma:  broc√©liand\n",
      "Token: - \tPOS:  PUNCT \tLemma:  -\n",
      "Token: Nausicaa \tPOS:  NOUN \tLemma:  nausicaa\n",
      "Token: et \tPOS:  CCONJ \tLemma:  et\n",
      "Token: C√©dric \tPOS:  PROPN \tLemma:  C√©dric\n",
      "Token: de \tPOS:  ADP \tLemma:  de\n",
      "Token: la \tPOS:  DET \tLemma:  le\n",
      "Token: Tour \tPOS:  NOUN \tLemma:  tour\n",
      "Token: de \tPOS:  ADP \tLemma:  de\n",
      "Token: la \tPOS:  DET \tLemma:  le\n",
      "Token: Terreur \tPOS:  NOUN \tLemma:  terreur\n",
      "__________________________________________________________________\n",
      "Vous souvenez-vous quand vous avez rejoint Twitter ? Moi, oui ! MonAnniversaireTwitter Que le temps passe vite. üò≠üò≠ je tiens √† vous remercier pour le soutien.\n",
      "Token: Vous \tPOS:  PRON \tLemma:  vous\n",
      "Token: souvenez \tPOS:  VERB \tLemma:  souvenir\n",
      "Token: -vous \tPOS:  PRON \tLemma:  vous\n",
      "Token: quand \tPOS:  SCONJ \tLemma:  quand\n",
      "Token: vous \tPOS:  PRON \tLemma:  vous\n",
      "Token: avez \tPOS:  AUX \tLemma:  avoir\n",
      "Token: rejoint \tPOS:  VERB \tLemma:  rejoindre\n",
      "Token: Twitter \tPOS:  PROPN \tLemma:  Twitter\n",
      "Token: ? \tPOS:  PUNCT \tLemma:  ?\n",
      "Token: Moi \tPOS:  NOUN \tLemma:  moi\n",
      "Token: , \tPOS:  PUNCT \tLemma:  ,\n",
      "Token: oui \tPOS:  ADV \tLemma:  oui\n",
      "Token: ! \tPOS:  PUNCT \tLemma:  !\n",
      "Token: MonAnniversaireTwitter \tPOS:  VERB \tLemma:  monanniversairetwitter\n",
      "Token: Que \tPOS:  SCONJ \tLemma:  que\n",
      "Token: le \tPOS:  DET \tLemma:  le\n",
      "Token: temps \tPOS:  NOUN \tLemma:  temps\n",
      "Token: passe \tPOS:  VERB \tLemma:  passer\n",
      "Token: vite \tPOS:  ADV \tLemma:  vite\n",
      "Token: . \tPOS:  PUNCT \tLemma:  .\n",
      "Token: üò≠ \tPOS:  ADV \tLemma:  üò≠\n",
      "Token: üò≠ \tPOS:  VERB \tLemma:  üò≠\n",
      "Token: je \tPOS:  PRON \tLemma:  je\n",
      "Token: tiens \tPOS:  VERB \tLemma:  tenir\n",
      "Token: √† \tPOS:  ADP \tLemma:  √†\n",
      "Token: vous \tPOS:  PRON \tLemma:  vous\n",
      "Token: remercier \tPOS:  VERB \tLemma:  remercier\n",
      "Token: pour \tPOS:  ADP \tLemma:  pour\n",
      "Token: le \tPOS:  DET \tLemma:  le\n",
      "Token: soutien \tPOS:  NOUN \tLemma:  soutien\n",
      "Token: . \tPOS:  PUNCT \tLemma:  .\n",
      "__________________________________________________________________\n",
      "Nous tenons √† remercier USER pour sa contribution. Sans son soutien, nous ne pourrions pas garantir que le Canada dispose d'une strat√©gie de d√©pistage et de sensibilisation par et pour la communaut√©.\n",
      "Token: Nous \tPOS:  PRON \tLemma:  nous\n",
      "Token: tenons \tPOS:  VERB \tLemma:  tenir\n",
      "Token: √† \tPOS:  ADP \tLemma:  √†\n",
      "Token: remercier \tPOS:  VERB \tLemma:  remercier\n",
      "Token: USER \tPOS:  VERB \tLemma:  user\n",
      "Token: pour \tPOS:  ADP \tLemma:  pour\n",
      "Token: sa \tPOS:  DET \tLemma:  son\n",
      "Token: contribution \tPOS:  NOUN \tLemma:  contribution\n",
      "Token: . \tPOS:  PUNCT \tLemma:  .\n",
      "Token: Sans \tPOS:  ADP \tLemma:  sans\n",
      "Token: son \tPOS:  DET \tLemma:  son\n",
      "Token: soutien \tPOS:  NOUN \tLemma:  soutien\n",
      "Token: , \tPOS:  PUNCT \tLemma:  ,\n",
      "Token: nous \tPOS:  PRON \tLemma:  nous\n",
      "Token: ne \tPOS:  ADV \tLemma:  ne\n",
      "Token: pourrions \tPOS:  VERB \tLemma:  pouvoir\n",
      "Token: pas \tPOS:  ADV \tLemma:  pas\n",
      "Token: garantir \tPOS:  VERB \tLemma:  garantir\n",
      "Token: que \tPOS:  SCONJ \tLemma:  que\n",
      "Token: le \tPOS:  DET \tLemma:  le\n",
      "Token: Canada \tPOS:  PROPN \tLemma:  Canada\n",
      "Token: dispose \tPOS:  VERB \tLemma:  dispose\n",
      "Token: d' \tPOS:  ADP \tLemma:  de\n",
      "Token: une \tPOS:  DET \tLemma:  un\n",
      "Token: strat√©gie \tPOS:  NOUN \tLemma:  strat√©gie\n",
      "Token: de \tPOS:  ADP \tLemma:  de\n",
      "Token: d√©pistage \tPOS:  NOUN \tLemma:  d√©pistage\n",
      "Token: et \tPOS:  CCONJ \tLemma:  et\n",
      "Token: de \tPOS:  ADP \tLemma:  de\n",
      "Token: sensibilisation \tPOS:  NOUN \tLemma:  sensibilisation\n",
      "Token: par \tPOS:  ADP \tLemma:  par\n",
      "Token: et \tPOS:  CCONJ \tLemma:  et\n",
      "Token: pour \tPOS:  ADP \tLemma:  pour\n",
      "Token: la \tPOS:  DET \tLemma:  le\n",
      "Token: communaut√© \tPOS:  NOUN \tLemma:  communaut√©\n",
      "Token: . \tPOS:  PUNCT \tLemma:  .\n",
      "__________________________________________________________________\n",
      "Remerciements adress√©s √† USER , USER et USER par tous ceux qui ont pris la parole, du repr√©sentant du site Kinyinya II au Conseiller du Gouverneur\n",
      "Token: Remerciements \tPOS:  NOUN \tLemma:  remerciement\n",
      "Token: adress√©s \tPOS:  VERB \tLemma:  adresser\n",
      "Token: √† \tPOS:  ADP \tLemma:  √†\n",
      "Token: USER \tPOS:  VERB \tLemma:  user\n",
      "Token: , \tPOS:  PUNCT \tLemma:  ,\n",
      "Token: USER \tPOS:  NOUN \tLemma:  user\n",
      "Token: et \tPOS:  CCONJ \tLemma:  et\n",
      "Token: USER \tPOS:  ADP \tLemma:  user\n",
      "Token: par \tPOS:  ADP \tLemma:  par\n",
      "Token: tous \tPOS:  ADJ \tLemma:  tout\n",
      "Token: ceux \tPOS:  PRON \tLemma:  celui\n",
      "Token: qui \tPOS:  PRON \tLemma:  qui\n",
      "Token: ont \tPOS:  AUX \tLemma:  avoir\n",
      "Token: pris \tPOS:  VERB \tLemma:  prendre\n",
      "Token: la \tPOS:  DET \tLemma:  le\n",
      "Token: parole \tPOS:  NOUN \tLemma:  parole\n",
      "Token: , \tPOS:  PUNCT \tLemma:  ,\n",
      "Token: du \tPOS:  ADP \tLemma:  de\n",
      "Token: repr√©sentant \tPOS:  NOUN \tLemma:  repr√©sentant\n",
      "Token: du \tPOS:  ADP \tLemma:  de\n",
      "Token: site \tPOS:  NOUN \tLemma:  site\n",
      "Token: Kinyinya \tPOS:  PROPN \tLemma:  Kinyinya\n",
      "Token: II \tPOS:  NUM \tLemma:  II\n",
      "Token: au \tPOS:  ADP \tLemma:  au\n",
      "Token: Conseiller \tPOS:  NOUN \tLemma:  conseiller\n",
      "Token: du \tPOS:  ADP \tLemma:  de\n",
      "Token: Gouverneur \tPOS:  NOUN \tLemma:  gouverneur\n",
      "__________________________________________________________________\n",
      "Nos sinc√®res remerciements aux agents.\n",
      "Token: Nos \tPOS:  DET \tLemma:  notre\n",
      "Token: sinc√®res \tPOS:  ADJ \tLemma:  sinc√®re\n",
      "Token: remerciements \tPOS:  NOUN \tLemma:  remerciement\n",
      "Token: aux \tPOS:  ADP \tLemma:  √†\n",
      "Token: agents \tPOS:  NOUN \tLemma:  agent\n",
      "Token: . \tPOS:  PUNCT \tLemma:  .\n",
      "__________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load matchers\n",
    "t_mat = load_t_matcher(patterns, nlp)\n",
    "\n",
    "# process documents\n",
    "docs = list(nlp.pipe(texts))\n",
    "\n",
    "\n",
    "# inspect relevant token attributes\n",
    "for doc in docs:\n",
    "    print(doc.text)\n",
    "    for t in doc:\n",
    "        print(\"Token:\", t.text, \"\\tPOS: \", t.tag_, \"\\tLemma: \", t.lemma_)\n",
    "    print(\"__________________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:\t En cette belle journ√©e pass√©e au royaume magique, je tiens √† remercier mille fois Broc√©liande-Nausicaa et C√©dric de la Tour de la Terreur\n",
      "This document contains gratitude.\n",
      "Captured patterns:\t ['je/nous/on - tenir - √† - remercier']\n",
      "Evidence:\t ['je tiens √† remercier']\n",
      "_______________________________________\n",
      "text:\t Vous souvenez-vous quand vous avez rejoint Twitter ? Moi, oui ! MonAnniversaireTwitter Que le temps passe vite. üò≠üò≠ je tiens √† vous remercier pour le soutien.\n",
      "This document contains gratitude.\n",
      "Captured patterns:\t ['je/nous/on - tenir - √† - vous/te/les/le/la - remercier']\n",
      "Evidence:\t ['je tiens √† vous remercier']\n",
      "_______________________________________\n",
      "text:\t Nous tenons √† remercier USER pour sa contribution. Sans son soutien, nous ne pourrions pas garantir que le Canada dispose d'une strat√©gie de d√©pistage et de sensibilisation par et pour la communaut√©.\n",
      "This document contains gratitude.\n",
      "Captured patterns:\t ['je/nous/on - tenir - √† - remercier']\n",
      "Evidence:\t ['Nous tenons √† remercier']\n",
      "_______________________________________\n",
      "text:\t Remerciements adress√©s √† USER , USER et USER par tous ceux qui ont pris la parole, du repr√©sentant du site Kinyinya II au Conseiller du Gouverneur\n",
      "This document contains gratitude.\n",
      "Captured patterns:\t ['remerciement - adress√© - √†']\n",
      "Evidence:\t ['Remerciements adress√©s √†']\n",
      "_______________________________________\n",
      "text:\t Nos sinc√®res remerciements aux agents.\n",
      "This document contains gratitude.\n",
      "Captured patterns:\t ['nos/mes - sinc√®res/... - remerciments/...']\n",
      "Evidence:\t ['Nos sinc√®res remerciements']\n",
      "_______________________________________\n"
     ]
    }
   ],
   "source": [
    "# check predictions\n",
    "for doc in docs:\n",
    "    print(\"text:\\t\", doc.text)    \n",
    "    appre, pat, seq = run_baseline_fr(nlp, doc, t_mat)\n",
    "    if appre:\n",
    "        print(\"This document contains gratitude.\")\n",
    "        print(\"Captured patterns:\\t\", pat)\n",
    "        print(\"Evidence:\\t\", seq)\n",
    "        print(\"_______________________________________\")\n",
    "        \n",
    "    else:\n",
    "        print(\"This document contains no gratitude.\")\n",
    "        print(\"_______________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87706ae1f7c88ada2fe1cb596284f7cb702f35161953f015589bf595d5a05225"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('gvenv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
